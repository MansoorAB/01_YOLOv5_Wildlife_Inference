{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: When running on Colab, make sure to set Hardware Accelarator to GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 System configuration Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check env for local run\n",
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi # for GPU specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvcc --version #to check CUDA version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat /etc/os-release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "use_cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Pytorch installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_cuda:\n",
    "    print('GPU found, proceeding with CUDA installation...')\n",
    "    !pip install torch==1.8.2+cu111 torchvision==0.9.2+cu111 torchaudio==0.8.2 -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html\n",
    "else:\n",
    "    print('GPU is not found, proceeding with CPU version installation...')\n",
    "    !pip install torch==1.8.2+cpu torchvision==0.9.2+cpu torchaudio===0.8.2 -f https://download.pytorch.org/whl/lts/1.8/torch_lts.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### all imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "import zipfile\n",
    "import pathlib\n",
    "import random\n",
    "import string\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Clone ultralytics repo and install the requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd yolov5 && pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Define various paths and create folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'DATA_PATH'  : os.path.join('data'),\n",
    "    'IMAGES_PATH': os.path.join('data', 'images'),\n",
    "    'LABELS_PATH': os.path.join('data', 'labels'),\n",
    "    'VIDEOS_PATH': os.path.join('data', 'videos'),\n",
    "    'INFER_PATH' : os.path.join('data', 'inference')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "            \n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2. Data Preparation (Local run only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download required images from intenet and keep them in data/images folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Rename images in serial order for easy reference. It will be like image001.jpg, image002.png etc..,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_files(path, file_index=1, prefix=None):\n",
    "    \n",
    "    # prefix: This is the common name part of the file name (program will autogenerate 5 letter code, if nothing is passed)\n",
    "    # file_index: files will be renamed img001.jpg etc.., if 100, files will be renamed img100.jpg etc..,\n",
    "    \n",
    "    if prefix is None:\n",
    "        prefix = ''.join(random.choices(string.ascii_uppercase, k=5))   \n",
    "\n",
    "    for rootdir, subdir, files in os.walk(path):\n",
    "        for file in files:\n",
    "            file_extension = pathlib.Path(file).suffix.strip()\n",
    "            old_file = os.path.join(path, file)\n",
    "            new_file = os.path.join(path, prefix + f\"{file_index:03}\" + file_extension)\n",
    "            os.rename(old_file, new_file)\n",
    "            file_index += 1\n",
    "            \n",
    "    print('Files renamed as per \"{}...\" pattern.'.format(prefix)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename the files from images folder\n",
    "rename_files(paths['IMAGES_PATH'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Use labelimg to do annotations in YOLO format. Image direcotry should be data/images and label directory should be data/labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Manually move files from images folder to images/train, images/validation so that folder contains a fair representation of all classes including background images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths.update ({\n",
    "    'IMAGES_TRAIN': os.path.join('data', 'images', 'train'),\n",
    "    'IMAGES_VAL': os.path.join('data', 'images', 'validation'),\n",
    "    'LABELS_TRAIN': os.path.join('data', 'labels', 'train'),\n",
    "    'LABELS_VAL': os.path.join('data', 'labels', 'validation'),\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "            \n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Then run the below script to move the respective label files to labels/train, labels/validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "num_train = num_val = num_train_bg = num_val_bg = 0\n",
    "\n",
    "train_files = [f for f in listdir(paths['IMAGES_TRAIN']) if isfile(join(paths['IMAGES_TRAIN'], f))]\n",
    "val_files = [f for f in listdir(paths['IMAGES_VAL']) if isfile(join(paths['IMAGES_VAL'], f))]\n",
    "\n",
    "for file in train_files:\n",
    "    fname, fext = file.split('.')\n",
    "    try:\n",
    "        num_train += 1\n",
    "        shutil.move(os.path.join(paths['LABELS_PATH'], fname + \".txt\"), paths['LABELS_TRAIN'])         \n",
    "    except Exception as e:\n",
    "        num_train_bg += 1\n",
    "        \n",
    "for file in val_files:\n",
    "    fname, fext = file.split('.')\n",
    "    try:\n",
    "        num_val += 1\n",
    "        shutil.move(os.path.join(paths['LABELS_PATH'], fname + \".txt\"), paths['LABELS_VAL'])         \n",
    "    except Exception as e:\n",
    "        num_val_bg += 1        \n",
    "        \n",
    "        \n",
    "print('Train images: {}; Validation images: {}; Train Background images: {}; Validation Background images: {}'\n",
    "                                  .format(num_train, num_val, num_train_bg, num_val_bg))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3. Data setup (for Colab only) \n",
    "\n",
    "### use one of the below options to get the data.\n",
    "\n",
    "### 3.1 zip the local data folder, manually upload to colab and unzip using the below command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command to zip the local data folder\n",
    "!tar -czf {'data_archive.tar.gz'} {paths['DATA_PATH']}\n",
    "print('Archiving data file is now complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# command to unzip the folder from google colab\n",
    "!tar -zxvf {'data_archive.tar.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Keep the data folder contents to your google drive and run the below command to copy to colab workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change location as per your GD structure\n",
    "!cp -r 'drive/MyDrive/Colab Notebooks/Git Projects Data/Wildlife Inference/data' ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Run the below commands to verify the number of images in each of the folders (local vs colab) are same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/images/train | wc -l\n",
    "!ls data/images/validation | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/labels/train | wc -l \n",
    "!ls data/labels/validation | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4. Load Out of box Model from torch hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s') # or yolov5m, yolov5l, yolov5x, custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Image Detection with Out of box model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = 'https://images.news18.com/ibnlive/uploads/2021/10/animal-day-16332888954x3.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = 'https://ultralytics.com/images/zidane.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = model(img)\n",
    "results.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "plt.rcParams[\"figure.figsize\"] = (20,8)\n",
    "plt.imshow(np.squeeze(results.render()))\n",
    "plt.savefig(os.path.join(paths['INFER_PATH'], 'img_001' + '.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5. Prepare custom images (For webcam use only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid   # Unique identifier\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_PATH = os.path.join('data', 'images') #/data/images\n",
    "labels = ['awake', 'drowsy']\n",
    "number_imgs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "# Loop through labels\n",
    "for label in labels:\n",
    "    print('Collecting images for {}'.format(label))\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Loop through image range\n",
    "    for img_num in range(number_imgs):\n",
    "        print('Collecting images for {}, image number {}'.format(label, img_num))\n",
    "        \n",
    "        # Webcam feed\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        # Naming out image path\n",
    "        imgname = os.path.join(IMAGES_PATH, label+'.'+str(uuid.uuid1())+'.jpg')\n",
    "        \n",
    "        # Writes out image to file \n",
    "        cv2.imwrite(imgname, frame)\n",
    "        \n",
    "        # Render to the screen\n",
    "        cv2.imshow('Image Collection', frame)\n",
    "        \n",
    "        # 2 second delay between captures\n",
    "        time.sleep(2)\n",
    "        \n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.path.join(IMAGES_PATH, labels[0]+'.'+str(uuid.uuid1())+'.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in labels:\n",
    "    print('Collecting images for {}'.format(label))\n",
    "    for img_num in range(number_imgs):\n",
    "        print('Collecting images for {}, image number {}'.format(label, img_num))\n",
    "        imgname = os.path.join(IMAGES_PATH, label+'.'+str(uuid.uuid1())+'.jpg')\n",
    "        print(imgname)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/tzutalin/labelImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install pyqt5 lxml --upgrade\n",
    "!cd labelImg && pyrcc5 -o libs/resources.py resources.qrc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 6. Custom Training (after images, labels folders are updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Keep the .yaml file in GD as per the dataset and run the below command to copy it to yolov5 folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp 'drive/MyDrive/Colab Notebooks/Git Projects Data/Wildlife Inference/wildlife.yaml' 'yolov5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 If using past weights, keep it in GD and run the below command to copy them to yolov5 folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cp -r 'drive/MyDrive/Colab Notebooks/Git Projects Data/Wildlife Inference/weights' 'yolov5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Run the below cell to start the training process (change --weights param as needed to point local file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd yolov5 && python train.py --img 640 --batch 16 --epochs 300 --data wildlife.yaml --weights yolov5s.pt --workers 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 zip the weights file on Colab space to manually export it to local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip experminet folder and manually export to local machine\n",
    "!tar -czf exp_small.tar.gz {'yolov5/runs/train/exp'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 7. Custom Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Load Custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if use_cuda:\n",
    "    model = torch.hub.load('ultralytics/yolov5', 'custom', path='yolov5/runs/train/exp/weights/best.pt', force_reload=True)\n",
    "else:\n",
    "    model = torch.hub.load('ultralytics/yolov5', 'custom', path='exp/weights/best.pt', force_reload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Image inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = 'https://images.news18.com/ibnlive/uploads/2021/10/animal-day-16332888954x3.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = model(img)\n",
    "results.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "plt.rcParams[\"figure.figsize\"] = (20,8)\n",
    "plt.imshow(np.squeeze(results.render()))\n",
    "plt.savefig(os.path.join(paths['INFER_PATH'], 'img_001' + '.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Recorded Video Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = 'Wildlife-002.mp4' \n",
    "video_input = os.path.join(paths['VIDEOS_PATH'], video_name)\n",
    "\n",
    "import tkinter as tk\n",
    "\n",
    "root = tk.Tk()\n",
    "\n",
    "screen_width = root.winfo_screenwidth()\n",
    "screen_height = root.winfo_screenheight()\n",
    "\n",
    "screen_width, screen_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "start_time = datetime.now()\n",
    "\n",
    "print('Inference started at: {}'.format(start_time.strftime(\"%I:%M:%S %p\")))\n",
    "\n",
    "cap = cv2.VideoCapture(video_input) # 0 for webcam\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MP4V')\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)  # 15.0, set the video fps\n",
    "out = cv2.VideoWriter(os.path.join(paths['INFER_PATH'], video_name), fourcc, fps, (screen_width, screen_height))\n",
    "time.sleep(0.5) #delay to allow camera to load the feed\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break    \n",
    "    \n",
    "    #make detections\n",
    "    results = model(frame)\n",
    "    op = np.squeeze(results.render())\n",
    "    out.write(cv2.resize(op, (screen_width, screen_height))) # (640, 480), (1280, 720), (screen_width, screen_height)    \n",
    "\n",
    "    #temporarily, comment the below cv2.imshow line for colab run. To be fixed\n",
    "    cv2.imshow('YOLOv5 Inference - Recorded video', op)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "end_time = datetime.now()\n",
    "\n",
    "print('Inference ended at: {}'.format(end_time.strftime(\"%I:%M:%S %p\")))\n",
    "print('Time taken for inference: {}'.format(end_time - start_time))                  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo_v5",
   "language": "python",
   "name": "yolo_v5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
